{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig. 5 panel A aligned umap\n",
    "\n",
    "please first run dependency notebooks in the following directories:\n",
    "- infected_enrichment\n",
    "- control_enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, os, sys\n",
    "from pathlib import Path\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "script_path = Path.cwd().parent.parent.parent.parent  / \"script\"\n",
    "data_path = Path.cwd().parent.parent.parent.parent  / \"data\"\n",
    "sys.path.append(str(script_path))\n",
    "\n",
    "from pyseus.plotting import plotly_umap as pu\n",
    "from utils import *\n",
    "\n",
    "output_folder = Path.cwd() / \"output\"\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load enrichment tables (for both infected and uninfected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 2023-10-21-for-figures\n"
     ]
    }
   ],
   "source": [
    "%store -r fig5_timestamp\n",
    "print(f\"Timestamp: {fig5_timestamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimenensions of loaded enrichment tables (uninfected, infected) are:\n",
      "(8537, 50)\n",
      "(8376, 51)\n"
     ]
    }
   ],
   "source": [
    "# load enrichment tables\n",
    "\n",
    "#require uninfected samples to match infected samples\n",
    "uninf_match_inf = True\n",
    "\n",
    "uninfected_enrichment_path = Path.cwd().parent / \"2.control_enrichment\" / \"output\" / \"enrichment_and_volcano_tables\" / f'{fig5_timestamp}_uninf_enrichment_table_NOC_prop.csv'\n",
    "infected_enrichment_path = Path.cwd().parent / \"1.infected_enrichment\" / \"output\" / \"enrichment_and_volcano_tables\" / f'{fig5_timestamp}_inf_enrichment_table_NOC_prop.csv'\n",
    "\n",
    "try:\n",
    "    enrichments_uninfected = pd.read_csv(uninfected_enrichment_path, header=[0, 1], index_col=0, low_memory=False)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File {uninfected_enrichment_path} not found.\\n please run the uninfected_enrichment notebooks first.\")\n",
    "except pd.errors.ParserError:\n",
    "    print(f\"There was an error parsing the CSV file at {uninfected_enrichment_path}.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "try:\n",
    "    enrichments_infected = pd.read_csv(infected_enrichment_path, header=[0, 1], index_col=0, low_memory=False)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File {infected_enrichment_path} not found.\\n please run the infected_enrichment notebooks first.\")\n",
    "except pd.errors.ParserError:\n",
    "    print(f\"There was an error parsing the CSV file at {infected_enrichment_path}.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "print(\"The dimenensions of loaded enrichment tables (uninfected, infected) are:\")\n",
    "print(enrichments_uninfected.shape)\n",
    "print(enrichments_infected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop multi-index\n",
    "enrichments_uninfected = enrichments_uninfected.droplevel(0, axis=1)\n",
    "enrichments_infected = enrichments_infected.droplevel(0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename NOC fractions\n",
    "enrichments_uninfected.rename(columns={\"NOC_cytosol_UnInfected\": \"NOC_cytosol\"}, inplace=True)\n",
    "enrichments_uninfected.rename(columns={\"NOC_organelle_UnInfected\": \"NOC_organelle\"}, inplace=True)\n",
    "enrichments_uninfected.rename(columns={\"NOC_nuclear_UnInfected\": \"NOC_nuclear\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the sample columns\n",
    "uninfected_cols = [\n",
    "    i for i in enrichments_uninfected.columns\n",
    "    if i.startswith((\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"NOC\"))\n",
    "]\n",
    "infected_cols = [\n",
    "    i for i in enrichments_infected.columns\n",
    "    if i.startswith((\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"NOC\"))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample exclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_table_uninfected = enrichments_uninfected[uninfected_cols]\n",
    "umap_table_infected = enrichments_infected[infected_cols]\n",
    "\n",
    "meta_cols = [\"Protein IDs\", \"Majority protein IDs\", \"Gene names\"]\n",
    "\n",
    "# remove non-relavent samples from the mass spectrometry master file\n",
    "uninfected_cols_filtered = [\n",
    "    x for x in uninfected_cols\n",
    "    if \"WT\" not in x and \"harsh\" not in x\n",
    "]\n",
    "infected_cols_filtered = [\n",
    "    x for x in infected_cols\n",
    "    if \"WT\" not in x and \"harsh\" not in x\n",
    "]\n",
    "umap_table_uninfected = enrichments_uninfected[meta_cols + uninfected_cols_filtered]\n",
    "umap_table_infected = enrichments_infected[[\"Protein IDs\"] + infected_cols_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excluded: ['09-PSMB7', '09-HSP90AA1', '10-AP2B1', '10-EXOC2', '09-PSMB7_Infected', '09-HSP90AA1_Infected', '10-AP2B1_Infected', '10-EXOC2_Infected']\n"
     ]
    }
   ],
   "source": [
    "# remove non-informative IPs from the mass spectrometry master file; these correspond to IPs for soluble targets that peripherally bind membranes\n",
    "# these IPs were not successful at pulling down membrane compartments, and were therefore removed from subsequent analyses\n",
    "exclude_list = ['09-PSMB7', '09-HSP90AA1', '10-AP2B1', \"10-EXOC2\"] \n",
    "excl_name = 'excl_' + '_'.join(exclude_list)\n",
    "exclude_list = exclude_list + [f\"{i}_Infected\" for i in exclude_list]\n",
    "print(f\"excluded: {exclude_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove virus proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_table_uninfected = umap_table_uninfected[~umap_table_uninfected[\"Protein IDs\"].str.contains(\"OC43\")]\n",
    "umap_table_infected = umap_table_infected[~umap_table_infected[\"Protein IDs\"].str.contains(\"OC43\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "match uninfected and infected samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tally the infected samples\n",
    "cols = umap_table_infected.columns\n",
    "cols_NOC = [i for i in cols if i.split(\"_\")[0] == \"NOC\"]\n",
    "cols_sams = [i for i in cols if i.split(\"-\")[0].isdigit()]\n",
    "# remove samples\n",
    "cols_sams = [i for i in cols_sams if i not in exclude_list]\n",
    "\n",
    "cols_inf = sorted(cols_sams) + cols_NOC\n",
    "\n",
    "# uncomment to print the sample names\n",
    "# printout = \"\"\n",
    "# for idx, val in enumerate(cols_inf):\n",
    "#     if idx > 0:\n",
    "#         if val.split('-')[0] == cols_inf[idx-1].split('-')[0]:\n",
    "#             printout += f\", {val}\"\n",
    "#         else:\n",
    "#             printout += f\"\\n{val}\"\n",
    "#     else:\n",
    "#         printout += f\"\\n{val}\"\n",
    "# print(\"infected samples to use:\")\n",
    "# print(printout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match between infected and uninfected samples\n",
    "# generate an uninfected sample list that have the same samples as the infected\n",
    "def in_list_ele(ele, lst):\n",
    "    for i in lst:\n",
    "        if ele in i:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "cols_uninf_match = []\n",
    "for i in umap_table_uninfected.columns:\n",
    "    if in_list_ele(i, cols_inf) and i not in [\"organelle\"]:\n",
    "        cols_uninf_match.append(i)\n",
    "cols_uninf_match = sorted(cols_uninf_match)\n",
    "\n",
    "# uncomment to print the sample names\n",
    "# printout = \"\"\n",
    "# for idx, val in enumerate(cols_uninf_match):\n",
    "#     if idx > 0:\n",
    "#         if val.split('-')[0] == cols_uninf_match[idx-1].split('-')[0]:\n",
    "#             printout += f\", {val}\"\n",
    "#         else:\n",
    "#             printout += f\"\\n{val}\"\n",
    "#     else:\n",
    "#         printout += f\"\\n{val}\"\n",
    "# print(\"Uninfected samples that match infected samples:\")\n",
    "# print(printout)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge uninfected and infected enrichment tables  \n",
    "the merged tables will have superfluous columns, and we keep track of sample for aligned UMAP with these two lists of column names: ``cols_uninf_matched`` and ``cols_inf``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the two umap tables (uninfected and infected)\n",
    "merged = umap_table_uninfected.merge(umap_table_infected, how='inner', on='Protein IDs', suffixes=[\"_uninf\", \"_inf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the samples that are not in the matched list\n",
    "for col_to_drop in exclude_list:\n",
    "    merged.drop(col_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninfected samples used for aligned UMAP:\n",
      "\n",
      "09-ATG101, 09-EDC4, 09-PEX3, 09-TOMM20\n",
      "10-RTN4, 10-TOMM20, 10-VPS35\n",
      "11-CEP350, 11-EEA1, 11-GPR107, 11-SEC31A\n",
      "12-LAMP1, 12-YWHAQ\n",
      "14-COPE, 14-GOLGA2, 14-RAB11A, 14-RAB14, 14-RAB1A, 14-RAB7A\n",
      "17-ATP1B3, 17-CAPRIN1, 17-G3BP1, 17-MAP1LC3B, 17-RPL36, 17-SLC30A2\n",
      "NOC_cytosol\n",
      "NOC_nuclear\n",
      "NOC_organelle\n",
      "\n",
      "Infected samples used for aligned UMAP:\n",
      "\n",
      "09-ATG101_Infected, 09-EDC4_Infected, 09-PEX3_Infected, 09-TOMM20_Infected\n",
      "10-RTN4_Infected, 10-TOMM20_Infected, 10-VPS35_Infected\n",
      "11-CEP350_Infected, 11-EEA1_Infected, 11-GPR107_Infected, 11-SEC31A_Infected\n",
      "12-LAMP1_Infected, 12-YWHAQ_Infected\n",
      "14-COPE_Infected, 14-GOLGA2_Infected, 14-RAB11A_Infected, 14-RAB14_Infected, 14-RAB1A_Infected, 14-RAB7A_Infected\n",
      "17-ATP1B3_Infected, 17-CAPRIN1_Infected, 17-G3BP1_Infected, 17-MAP1LC3B_Infected, 17-RPL36_Infected, 17-SLC30A2_Infected\n",
      "NOC_cytosol_Infected\n",
      "NOC_nuclear_Infected\n",
      "NOC_organelle_Infected\n"
     ]
    }
   ],
   "source": [
    "# prepare objects for aligning umap\n",
    "\n",
    "# exclude the annotation columns\n",
    "excl = [\n",
    "    i for i in merged.columns\n",
    "    if not i.startswith((\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"NOC\"))\n",
    "]\n",
    "if uninf_match_inf:  # BOOL, if require uninfected samples to match infected samples\n",
    "    uninf = [i for i in merged.columns if i not in excl and i in cols_uninf_match]\n",
    "else:\n",
    "    uninf = [i for i in merged.columns if i not in excl and i in cols_uninf]\n",
    "inf = [i for i in merged.columns if i not in excl and i in cols_inf]\n",
    "\n",
    "# manually add NOC columns\n",
    "uninf = uninf + [\n",
    "    i for i in merged.columns if i.startswith(\"NOC\") and i.endswith(\"_uninf\")\n",
    "]\n",
    "inf = inf + [i for i in merged.columns if i.startswith(\"NOC\") and i.endswith(\"_inf\")]\n",
    "\n",
    "\n",
    "def nicely_print_samples(samples):\n",
    "    printout = \"\"\n",
    "    for idx, val in enumerate(samples):\n",
    "        if idx > 0:\n",
    "            if val.split(\"-\")[0] == samples[idx - 1].split(\"-\")[0]:\n",
    "                printout += f\", {val}\"\n",
    "            else:\n",
    "                printout += f\"\\n{val}\"\n",
    "        else:\n",
    "            printout += f\"\\n{val}\"\n",
    "    print(printout)\n",
    "\n",
    "\n",
    "print(\"Uninfected samples used for aligned UMAP:\")\n",
    "nicely_print_samples(sorted(uninf))\n",
    "print(\"\\nInfected samples used for aligned UMAP:\")\n",
    "nicely_print_samples(sorted(inf))\n",
    "\n",
    "embedding_uninfected = merged[uninf].copy().fillna(0).to_numpy()\n",
    "embedding_infected = merged[inf].copy().fillna(0).to_numpy()\n",
    "\n",
    "# scale the data\n",
    "embedding_uninfected = pu.scale_table(matrix=embedding_uninfected, method=\"standard\")\n",
    "embedding_infected = pu.scale_table(matrix=embedding_infected, method=\"standard\")\n",
    "\n",
    "embeddings = [embedding_uninfected, embedding_infected]\n",
    "\n",
    "constant_dict = {i: i for i in range(len(embedding_uninfected))}\n",
    "constant_relations = [constant_dict for i in range(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data for other analyses, e.g. Leiden clustering etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\duo.peng\\Anaconda3\\envs\\OrgIP2\\lib\\site-packages\\anndata\\_core\\anndata.py:121: ImplicitModificationWarning:\n",
      "\n",
      "Transforming to str index.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generating AnnData for Leiden\n",
    "selected = merged[uninf].copy().fillna(0)\n",
    "adata = ad.AnnData(selected, dtype=np.float32)\n",
    "\n",
    "adata.obs_names = merged[\"Protein IDs\"].to_list()\n",
    "adata.var_names = merged[uninf].columns.to_list()\n",
    "adata.obs[\"Protein IDs\"] = merged[\"Protein IDs\"].to_list()\n",
    "adata.obs[\"Majority protein IDs\"] = merged[\"Majority protein IDs\"].to_list()\n",
    "adata.obs[\"Gene names\"] = merged[\"Gene names\"].to_list()\n",
    "\n",
    "# save the adata object to file\n",
    "adata.write(output_folder / f\"[for_leiden]_adata_aln_uninf.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\duo.peng\\Anaconda3\\envs\\OrgIP2\\lib\\site-packages\\anndata\\_core\\anndata.py:121: ImplicitModificationWarning:\n",
      "\n",
      "Transforming to str index.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generating AnnData for Leiden\n",
    "selected = merged[inf].copy().fillna(0)\n",
    "adata = ad.AnnData(selected, dtype=np.float32)\n",
    "\n",
    "adata.obs_names = merged[\"Protein IDs\"].to_list()\n",
    "adata.var_names = merged[inf].columns.to_list()\n",
    "adata.obs[\"Protein IDs\"] = merged[\"Protein IDs\"].to_list()\n",
    "adata.obs[\"Majority protein IDs\"] = merged[\"Majority protein IDs\"].to_list()\n",
    "adata.obs[\"Gene names\"] = merged[\"Gene names\"].to_list()\n",
    "\n",
    "# save the adata object to file\n",
    "adata.write(output_folder / f\"[for_leiden]_adata_aln_inf.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligned UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a helper function\n",
    "def calculate_distance(neighbors_mapper):\n",
    "    '''Calculate (for each point) the distance between the the aligned UMAPs\n",
    "    Input: neighbors_mapper object\n",
    "    '''\n",
    "    #extract coordinates\n",
    "    JointUMAP_uninf_1 = list(neighbors_mapper.embeddings_[0].T[0])\n",
    "    JointUMAP_uninf_2 = list(neighbors_mapper.embeddings_[0].T[1])\n",
    "    JointUMAP_inf_1 = list(neighbors_mapper.embeddings_[1].T[0])\n",
    "    JointUMAP_inf_2 = list(neighbors_mapper.embeddings_[1].T[1])\n",
    "\n",
    "    coordinate_uninf = list(zip(JointUMAP_uninf_1, JointUMAP_uninf_2))\n",
    "    coordinate_inf = list(zip(JointUMAP_inf_1, JointUMAP_inf_2))\n",
    "\n",
    "    # calculate the distance between the two coordinates\n",
    "    distances = []\n",
    "    for idx, val in enumerate(coordinate_uninf):\n",
    "        distance = math.dist(val, coordinate_inf[idx])\n",
    "        distances.append(distance)\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D aligned umap (for visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate aligned umap\n",
    "neighbors_mapper = umap.AlignedUMAP(\n",
    "    n_neighbors=20,\n",
    "    metric=\"euclidean\",\n",
    "    min_dist=0.1,\n",
    "    # alignment_window_size=2,\n",
    "    alignment_regularisation=0.002,  # This value was optimized using a sweep. Larger values of alignment_regularisation will work harder to keep points aligned across embeddings (at the cost of the embedding quality at each slice), while smaller values will allow the optimisation to focus more on the individual embeddings and put less emphasis on aligning the embeddings with each other.\n",
    "    n_epochs=300,  # This value was optimized using a sweep.\n",
    "    random_state=42,\n",
    "    verbose=False,\n",
    "    n_components=2,\n",
    ").fit(embeddings, relations=constant_relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10D aligned umap (for remodeling score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run 200 times, using different seeds, takes 5 hours  \n",
    "to reduce run time, set a smaller number of runs, e.g. n_seeds = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af74d6447fad4038a5b9dedc9d5adc9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating aligned UMAPs:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# (takes about 4 hours on a laptop, and can't use multi-processing to parallelize b/c each instance of umap.AlignedUMAP is already parallelized when using random seeds)\n",
    "n_seeds = 200\n",
    "if n_seeds < 100:\n",
    "    print(\"WARNING:\\nn_seeds is less than 100, which may not be enough to calculate the coefficient of variation accurately.\")\n",
    "list_of_alignments = []\n",
    "for i in tqdm(range(0, n_seeds), desc=\"Calculating aligned UMAPs\", total=n_seeds):\n",
    "# for i in range(0, 200):\n",
    "    _neighbors_mapper = umap.AlignedUMAP(\n",
    "        n_neighbors=20,\n",
    "        metric=\"euclidean\",\n",
    "        min_dist=0.1,\n",
    "        #alignment_window_size=2,\n",
    "        alignment_regularisation=0.002,  # Larger values of alignment_regularisation will work harder to keep points aligned across embeddings (at the cost of the embedding quality at each slice), while smaller values will allow the optimisation to focus more on the individual embeddings and put less emphasis on aligning the embeddings with each other.\n",
    "        n_epochs=300,\n",
    "        random_state=None,  # calculate aligned UMAPs with different random seeds\n",
    "        verbose=False,\n",
    "        n_components=10,\n",
    "    ).fit(embeddings, relations=constant_relations)\n",
    "    list_of_alignments.append(_neighbors_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the distance for each alignment\n",
    "\n",
    "distances = []\n",
    "for idx, val in enumerate(list_of_alignments):\n",
    "    _distance = calculate_distance(val)\n",
    "    distances.append(_distance)\n",
    "\n",
    "# calculate the mean of the distances\n",
    "dist_mean_10D = np.mean(distances, axis=0)\n",
    "# calculate the variance of the distances\n",
    "dist_variance_10D = np.var(distances, axis=0)\n",
    "# calculate the standard deviation of the distances\n",
    "dist_std_10D = np.std(distances, axis=0)\n",
    "# calculate the coefficient of variation of the distances\n",
    "dist_cv_10D = dist_std_10D / dist_mean_10D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D aligned umap (for remodeling score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run 200 times, using different seeds, takes 5 hours  \n",
    "to reduce run time, set a smaller number of runs, e.g. n_seeds = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7a9e88eed2415a9c9816b342e530c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating aligned UMAPs:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# (takes about 4 hours on a laptop, and can't use multi-processing to parallelize b/c each instance of umap.AlignedUMAP is already parallelized when using random seeds)\n",
    "n_seeds = 200\n",
    "if n_seeds < 100:\n",
    "    print(\"WARNING:\\nn_seeds is less than 100, which may not be enough to calculate the coefficient of variation accurately.\")\n",
    "list_of_alignments = []\n",
    "for i in tqdm(range(0, n_seeds), desc=\"Calculating aligned UMAPs\", total=n_seeds):\n",
    "# for i in range(0, 200):\n",
    "    _neighbors_mapper = umap.AlignedUMAP(\n",
    "        n_neighbors=20,\n",
    "        metric=\"euclidean\",\n",
    "        min_dist=0.1,\n",
    "        #alignment_window_size=2,\n",
    "        alignment_regularisation=0.002,  # Larger values of alignment_regularisation will work harder to keep points aligned across embeddings (at the cost of the embedding quality at each slice), while smaller values will allow the optimisation to focus more on the individual embeddings and put less emphasis on aligning the embeddings with each other.\n",
    "        n_epochs=300,\n",
    "        random_state=None,  # calculate aligned UMAPs with different random seeds\n",
    "        verbose=False,\n",
    "        n_components=2,\n",
    "    ).fit(embeddings, relations=constant_relations)\n",
    "    list_of_alignments.append(_neighbors_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the distance for each alignment\n",
    "\n",
    "distances = []\n",
    "for idx, val in enumerate(list_of_alignments):\n",
    "    _distance = calculate_distance(val)\n",
    "    distances.append(_distance)\n",
    "\n",
    "# calculate the mean of the distances\n",
    "dist_mean_2D = np.mean(distances, axis=0)\n",
    "# calculate the variance of the distances\n",
    "dist_variance_2D = np.var(distances, axis=0)\n",
    "# calculate the standard deviation of the distances\n",
    "dist_std_2D = np.std(distances, axis=0)\n",
    "# calculate the coefficient of variation of the distances\n",
    "dist_cv_2D = dist_std_2D / dist_mean_2D"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the 2D embeddings and 2D, 10D distances (along with other columns) to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'n_seeds' (int)\n"
     ]
    }
   ],
   "source": [
    "# save aligned umap embeddings to csv\n",
    "merged[\"JointUMAP_uninf_1\"] = neighbors_mapper.embeddings_[0].T[0]\n",
    "merged[\"JointUMAP_uninf_2\"] = neighbors_mapper.embeddings_[0].T[1]\n",
    "merged[\"JointUMAP_inf_1\"] = neighbors_mapper.embeddings_[1].T[0]\n",
    "merged[\"JointUMAP_inf_2\"] = neighbors_mapper.embeddings_[1].T[1]\n",
    "\n",
    "# save 2D distances to csv\n",
    "merged[f\"2d_mean_distance_traveled ({n_seeds} bootstraps)\"] = dist_mean_2D\n",
    "merged[f\"2d_coefficient_variance_distance_traveled ({n_seeds} bootstraps)\"] = dist_cv_2D\n",
    "\n",
    "# save 10D distances to csv\n",
    "merged[f\"10d_mean_distance_traveled ({n_seeds} bootstraps)\"] = dist_mean_10D\n",
    "merged[f\"10d_coefficient_variance_distance_traveled ({n_seeds} bootstraps)\"] = dist_cv_10D\n",
    "\n",
    "save_path = output_folder / f\"{fig5_timestamp}_AlignedUMAP_embeddings_and_distances.csv\"\n",
    "merged.to_csv(save_path, index=False)\n",
    "\n",
    "# save the number of seeds used to calculate the distances\n",
    "%store n_seeds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f9eaa72b302f95492a7962f765d4c258b54a123165a740f4464c5d6cbafb102"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
