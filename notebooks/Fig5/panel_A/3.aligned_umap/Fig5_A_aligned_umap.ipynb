{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig. 5 panel A aligned umap\n",
    "\n",
    "please first run dependency notebooks in the following directories:\n",
    "- infected_enrichment\n",
    "- control_enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, umap\n",
    "from pathlib import Path\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "script_path = Path.cwd().parent.parent.parent.parent  / \"script\"\n",
    "data_path = Path.cwd().parent.parent.parent.parent  / \"data\"\n",
    "sys.path.append(str(script_path))\n",
    "\n",
    "from pyseus.plotting import plotly_umap as pu\n",
    "from utils.aligned_umap import *\n",
    "\n",
    "output_folder = Path.cwd() / \"output\"\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load enrichment tables (for both infected and uninfected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 2023-10-21-for-figures\n"
     ]
    }
   ],
   "source": [
    "%store -r fig5_timestamp\n",
    "print(f\"Timestamp: {fig5_timestamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimenensions of loaded enrichment tables are:\n",
      "uninfected: (8537, 50)\n",
      "infected: (8376, 51)\n"
     ]
    }
   ],
   "source": [
    "# load enrichment tables\n",
    "\n",
    "# flag to designate if require uninfected samples to match infected samples\n",
    "uninf_match_inf = True\n",
    "\n",
    "uninfected_enrichment_path = Path.cwd().parent / \"2.control_enrichment\" / \"output\" / \"enrichment_and_volcano_tables\" / f'{fig5_timestamp}_uninf_enrichment_table_NOC_prop.csv'\n",
    "infected_enrichment_path = Path.cwd().parent / \"1.infected_enrichment\" / \"output\" / \"enrichment_and_volcano_tables\" / f'{fig5_timestamp}_inf_enrichment_table_NOC_prop.csv'\n",
    "\n",
    "try:\n",
    "    enrichments_uninfected = pd.read_csv(uninfected_enrichment_path, header=[0, 1], index_col=0, low_memory=False)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File {uninfected_enrichment_path} not found.\\n please run the uninfected_enrichment notebooks first.\")\n",
    "except pd.errors.ParserError:\n",
    "    print(f\"There was an error parsing the CSV file at {uninfected_enrichment_path}.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "try:\n",
    "    enrichments_infected = pd.read_csv(infected_enrichment_path, header=[0, 1], index_col=0, low_memory=False)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File {infected_enrichment_path} not found.\\n please run the infected_enrichment notebooks first.\")\n",
    "except pd.errors.ParserError:\n",
    "    print(f\"There was an error parsing the CSV file at {infected_enrichment_path}.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "print(\"The dimenensions of loaded enrichment tables are:\")\n",
    "print(f\"uninfected: {enrichments_uninfected.shape}\")\n",
    "print(f\"infected: {enrichments_infected.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop multi-index\n",
    "enrichments_uninfected = enrichments_uninfected.droplevel(0, axis=1)\n",
    "enrichments_infected = enrichments_infected.droplevel(0, axis=1)\n",
    "\n",
    "# rename NOC fractions\n",
    "enrichments_uninfected.rename(columns={\"NOC_cytosol_UnInfected\": \"NOC_cytosol\"}, inplace=True)\n",
    "enrichments_uninfected.rename(columns={\"NOC_organelle_UnInfected\": \"NOC_organelle\"}, inplace=True)\n",
    "enrichments_uninfected.rename(columns={\"NOC_nuclear_UnInfected\": \"NOC_nuclear\"}, inplace=True)\n",
    "\n",
    "# select the sample columns\n",
    "uninfected_cols = [\n",
    "    i for i in enrichments_uninfected.columns\n",
    "    if i.startswith((\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"NOC\"))\n",
    "]\n",
    "infected_cols = [\n",
    "    i for i in enrichments_infected.columns\n",
    "    if i.startswith((\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"NOC\"))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample exclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_table_uninfected = enrichments_uninfected[uninfected_cols]\n",
    "umap_table_infected = enrichments_infected[infected_cols]\n",
    "\n",
    "meta_cols = [\"Protein IDs\", \"Majority protein IDs\", \"Gene names\"]\n",
    "\n",
    "# remove non-relavent samples from the mass spectrometry master file\n",
    "uninfected_cols_filtered = [\n",
    "    x for x in uninfected_cols\n",
    "    if \"WT\" not in x and \"harsh\" not in x\n",
    "]\n",
    "infected_cols_filtered = [\n",
    "    x for x in infected_cols\n",
    "    if \"WT\" not in x and \"harsh\" not in x\n",
    "]\n",
    "umap_table_uninfected = enrichments_uninfected[meta_cols + uninfected_cols_filtered]\n",
    "umap_table_infected = enrichments_infected[[\"Protein IDs\"] + infected_cols_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excluded: ['09-PSMB7', '09-HSP90AA1', '10-AP2B1', '10-EXOC2', '09-PSMB7_Infected', '09-HSP90AA1_Infected', '10-AP2B1_Infected', '10-EXOC2_Infected']\n"
     ]
    }
   ],
   "source": [
    "# remove non-informative IPs from the mass spectrometry master file; these correspond to IPs for soluble targets that peripherally bind membranes\n",
    "# these IPs were not successful at pulling down membrane compartments, and were therefore removed from subsequent analyses\n",
    "exclude_list = ['09-PSMB7', '09-HSP90AA1', '10-AP2B1', \"10-EXOC2\"] \n",
    "excl_name = 'excl_' + '_'.join(exclude_list)\n",
    "exclude_list = exclude_list + [f\"{i}_Infected\" for i in exclude_list]\n",
    "print(f\"excluded: {exclude_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove virus proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_table_uninfected = umap_table_uninfected[~umap_table_uninfected[\"Protein IDs\"].str.contains(\"OC43\")]\n",
    "umap_table_infected = umap_table_infected[~umap_table_infected[\"Protein IDs\"].str.contains(\"OC43\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "match uninfected and infected samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infected samples columns\n",
    "cols = umap_table_infected.columns\n",
    "cols_NOC = [i for i in cols if i.split(\"_\")[0] == \"NOC\"]\n",
    "cols_sams = [i for i in cols if i.split(\"-\")[0].isdigit()]\n",
    "# apply the exclusion lists\n",
    "cols_sams = [i for i in cols_sams if i not in exclude_list]\n",
    "cols_inf = sorted(cols_sams) + cols_NOC\n",
    "\n",
    "# uncomment the following to print the infected sample names\n",
    "\n",
    "# printout = \"\"\n",
    "# for idx, val in enumerate(cols_inf):\n",
    "#     if idx > 0:\n",
    "#         if val.split('-')[0] == cols_inf[idx-1].split('-')[0]:\n",
    "#             printout += f\", {val}\"\n",
    "#         else:\n",
    "#             printout += f\"\\n{val}\"\n",
    "#     else:\n",
    "#         printout += f\"\\n{val}\"\n",
    "# print(\"infected samples to use:\")\n",
    "# print(printout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match between infected and uninfected samples\n",
    "# generate an uninfected sample list that have the same samples as the infected\n",
    "cols_uninf_match = []\n",
    "for i in umap_table_uninfected.columns:\n",
    "    if in_list_ele(i, cols_inf) and i not in [\"organelle\"]:\n",
    "        cols_uninf_match.append(i)\n",
    "cols_uninf_match = sorted(cols_uninf_match)\n",
    "\n",
    "# uncomment the following to print the uninfected sample names\n",
    "\n",
    "# printout = \"\"\n",
    "# for idx, val in enumerate(cols_uninf_match):\n",
    "#     if idx > 0:\n",
    "#         if val.split('-')[0] == cols_uninf_match[idx-1].split('-')[0]:\n",
    "#             printout += f\", {val}\"\n",
    "#         else:\n",
    "#             printout += f\"\\n{val}\"\n",
    "#     else:\n",
    "#         printout += f\"\\n{val}\"\n",
    "# print(\"uninfected samples that match infected samples:\")\n",
    "# print(printout)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge uninfected and infected enrichment tables  \n",
    "the merged tables will have superfluous columns, and we keep track of sample for aligned UMAP with these two lists of column names: ``cols_uninf_matched`` and ``cols_inf``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the two umap tables (uninfected and infected)\n",
    "merged = umap_table_uninfected.merge(umap_table_infected, how='inner', on='Protein IDs', suffixes=[\"_uninf\", \"_inf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the samples that are not in the matched list\n",
    "for col_to_drop in exclude_list:\n",
    "    merged.drop(col_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninfected samples used for aligned UMAP:\n",
      "\n",
      "09-ATG101, 09-EDC4, 09-PEX3, 09-TOMM20\n",
      "10-RTN4, 10-TOMM20, 10-VPS35\n",
      "11-CEP350, 11-EEA1, 11-GPR107, 11-SEC31A\n",
      "12-LAMP1, 12-YWHAQ\n",
      "14-COPE, 14-GOLGA2, 14-RAB11A, 14-RAB14, 14-RAB1A, 14-RAB7A\n",
      "17-ATP1B3, 17-CAPRIN1, 17-G3BP1, 17-MAP1LC3B, 17-RPL36, 17-SLC30A2\n",
      "NOC_cytosol\n",
      "NOC_nuclear\n",
      "NOC_organelle\n",
      "\n",
      "Infected samples used for aligned UMAP:\n",
      "\n",
      "09-ATG101_Infected, 09-EDC4_Infected, 09-PEX3_Infected, 09-TOMM20_Infected\n",
      "10-RTN4_Infected, 10-TOMM20_Infected, 10-VPS35_Infected\n",
      "11-CEP350_Infected, 11-EEA1_Infected, 11-GPR107_Infected, 11-SEC31A_Infected\n",
      "12-LAMP1_Infected, 12-YWHAQ_Infected\n",
      "14-COPE_Infected, 14-GOLGA2_Infected, 14-RAB11A_Infected, 14-RAB14_Infected, 14-RAB1A_Infected, 14-RAB7A_Infected\n",
      "17-ATP1B3_Infected, 17-CAPRIN1_Infected, 17-G3BP1_Infected, 17-MAP1LC3B_Infected, 17-RPL36_Infected, 17-SLC30A2_Infected\n",
      "NOC_cytosol_Infected\n",
      "NOC_nuclear_Infected\n",
      "NOC_organelle_Infected\n"
     ]
    }
   ],
   "source": [
    "# preprocessing for the aligning umap\n",
    "\n",
    "# exclude the annotation columns\n",
    "excl = [\n",
    "    i for i in merged.columns\n",
    "    if not i.startswith((\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"NOC\"))\n",
    "]\n",
    "if uninf_match_inf:  # BOOL, if require uninfected samples to match infected samples\n",
    "    uninf = [i for i in merged.columns if i not in excl and i in cols_uninf_match]\n",
    "else:\n",
    "    uninf = [i for i in merged.columns if i not in excl and i in cols_uninf]\n",
    "inf = [i for i in merged.columns if i not in excl and i in cols_inf]\n",
    "\n",
    "# manually add NOC columns\n",
    "uninf = uninf + [\n",
    "    i for i in merged.columns if i.startswith(\"NOC\") and i.endswith(\"_uninf\")\n",
    "]\n",
    "inf = inf + [i for i in merged.columns if i.startswith(\"NOC\") and i.endswith(\"_inf\")]\n",
    "\n",
    "print(\"Uninfected samples used for aligned UMAP:\")\n",
    "print_samples(sorted(uninf))\n",
    "print(\"\\nInfected samples used for aligned UMAP:\")\n",
    "print_samples(sorted(inf))\n",
    "\n",
    "embedding_uninfected = merged[uninf].copy().fillna(0).to_numpy()\n",
    "embedding_infected = merged[inf].copy().fillna(0).to_numpy()\n",
    "\n",
    "# scale the data\n",
    "embedding_uninfected = pu.scale_table(matrix=embedding_uninfected, method=\"standard\")\n",
    "embedding_infected = pu.scale_table(matrix=embedding_infected, method=\"standard\")\n",
    "embeddings = [embedding_uninfected, embedding_infected]\n",
    "\n",
    "# save the constant_relations for the aligned umap\n",
    "constant_dict = {i: i for i in range(len(embedding_uninfected))}\n",
    "constant_relations = [constant_dict for i in range(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data for other analyses, e.g. Leiden clustering etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\duo.peng\\Anaconda3\\envs\\OrgIP_zenodo\\lib\\site-packages\\anndata\\_core\\anndata.py:121: ImplicitModificationWarning:\n",
      "\n",
      "Transforming to str index.\n",
      "\n",
      "c:\\Users\\duo.peng\\Anaconda3\\envs\\OrgIP_zenodo\\lib\\site-packages\\anndata\\_core\\anndata.py:121: ImplicitModificationWarning:\n",
      "\n",
      "Transforming to str index.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (uninfected) generating an annData object for Leiden clustering algorithm\n",
    "selected = merged[uninf].copy().fillna(0)\n",
    "adata = ad.AnnData(selected, dtype=np.float32)\n",
    "adata.obs_names = merged[\"Protein IDs\"].to_list()\n",
    "adata.var_names = merged[uninf].columns.to_list()\n",
    "adata.obs[\"Protein IDs\"] = merged[\"Protein IDs\"].to_list()\n",
    "adata.obs[\"Majority protein IDs\"] = merged[\"Majority protein IDs\"].to_list()\n",
    "adata.obs[\"Gene names\"] = merged[\"Gene names\"].to_list()\n",
    "# save the adata object to file\n",
    "adata.write(output_folder / f\"[for_leiden]_adata_aln_uninf.h5ad\")\n",
    "\n",
    "# (infected) generating AnnData for Leiden\n",
    "selected = merged[inf].copy().fillna(0)\n",
    "adata = ad.AnnData(selected, dtype=np.float32)\n",
    "adata.obs_names = merged[\"Protein IDs\"].to_list()\n",
    "adata.var_names = merged[inf].columns.to_list()\n",
    "adata.obs[\"Protein IDs\"] = merged[\"Protein IDs\"].to_list()\n",
    "adata.obs[\"Majority protein IDs\"] = merged[\"Majority protein IDs\"].to_list()\n",
    "adata.obs[\"Gene names\"] = merged[\"Gene names\"].to_list()\n",
    "# save the adata object to file\n",
    "adata.write(output_folder / f\"[for_leiden]_adata_aln_inf.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligned UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D aligned umap (for visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate aligned umap\n",
    "neighbors_mapper = umap.AlignedUMAP(\n",
    "    n_neighbors=20,\n",
    "    metric=\"euclidean\",\n",
    "    min_dist=0.1,\n",
    "    # alignment_window_size=2,\n",
    "    alignment_regularisation=0.002,  # this value was optimized using a sweep. Larger values of alignment_regularisation will work harder to keep points aligned across embeddings (at the cost of the embedding quality at each slice), while smaller values will allow the optimisation to focus more on the individual embeddings and put less emphasis on aligning the embeddings with each other.\n",
    "    n_epochs=300,  # this value was optimized using a sweep.\n",
    "    random_state=42,\n",
    "    verbose=False,\n",
    "    n_components=2,\n",
    ").fit(embeddings, relations=constant_relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10D aligned umap (for remodeling score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run 50 times, using different seeds, takes 2 hours (we ran 200 times for the manuscript)  \n",
    "to reduce run time, set a smaller number of runs, e.g. n_seeds = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:\n",
      "n_seeds is less than 200, which may not be enough to calculate the coefficient of variation accurately. In the manuscript, we used 200 random seeds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa95878b27004d058ad69e6153bf27ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating aligned UMAPs:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# can't use multi-processing to parallelize b/c each instance of umap.AlignedUMAP is already parallelized when using random seeds\n",
    "n_seeds = 50\n",
    "if n_seeds < 200:\n",
    "    print('WARNING:\\nn_seeds is less than 200, '\n",
    "          'which may not be enough to calculate the coefficient of variation accurately. '\n",
    "          'In the manuscript, we used 200 random seeds.')\n",
    "list_of_alignments = []\n",
    "for i in tqdm(range(0, n_seeds), desc=\"Calculating aligned UMAPs\", total=n_seeds):\n",
    "    _neighbors_mapper = umap.AlignedUMAP(\n",
    "        n_neighbors=20,\n",
    "        metric=\"euclidean\",\n",
    "        min_dist=0.1,\n",
    "        #alignment_window_size=2,\n",
    "        alignment_regularisation=0.002,  # larger values of alignment_regularisation will work harder to keep points aligned across embeddings (at the cost of the embedding quality at each slice), while smaller values will allow the optimisation to focus more on the individual embeddings and put less emphasis on aligning the embeddings with each other.\n",
    "        n_epochs=300,\n",
    "        random_state=None,  # calculate aligned UMAPs with different random seeds\n",
    "        verbose=False,\n",
    "        n_components=10,\n",
    "    ).fit(embeddings, relations=constant_relations)\n",
    "    list_of_alignments.append(_neighbors_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the distance for each alignment\n",
    "distances = []\n",
    "for idx, val in enumerate(list_of_alignments):\n",
    "    _distance = calculate_distance(val)\n",
    "    distances.append(_distance)\n",
    "\n",
    "# calculate the mean of the distances\n",
    "dist_mean_10D = np.mean(distances, axis=0)\n",
    "# calculate the variance of the distances\n",
    "dist_variance_10D = np.var(distances, axis=0)\n",
    "# calculate the standard deviation of the distances\n",
    "dist_std_10D = np.std(distances, axis=0)\n",
    "# calculate the coefficient of variation of the distances\n",
    "dist_cv_10D = dist_std_10D / dist_mean_10D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D aligned umap (for remodeling score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run 50 times, using different seeds, takes 2 hours (we ran 200 times for the manuscript)  \n",
    "to reduce run time, set a smaller number of runs, e.g. n_seeds = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:\n",
      "n_seeds is less than 200, which may not be enough to calculate the coefficient of variation accurately. In the manuscript, we used 200 random seeds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b44956da9f40d2aef4994b97751d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating aligned UMAPs:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# can't use multi-processing to parallelize b/c each instance of umap.AlignedUMAP is already parallelized when using random seeds\n",
    "if n_seeds < 200:\n",
    "    print('WARNING:\\nn_seeds is less than 200, '\n",
    "          'which may not be enough to calculate the coefficient of variation accurately. '\n",
    "          'In the manuscript, we used 200 random seeds.')\n",
    "list_of_alignments = []\n",
    "for i in tqdm(range(0, n_seeds), desc=\"Calculating aligned UMAPs\", total=n_seeds):\n",
    "    _neighbors_mapper = umap.AlignedUMAP(\n",
    "        n_neighbors=20,\n",
    "        metric=\"euclidean\",\n",
    "        min_dist=0.1,\n",
    "        #alignment_window_size=2,\n",
    "        alignment_regularisation=0.002,  # larger values of alignment_regularisation will work harder to keep points aligned across embeddings (at the cost of the embedding quality at each slice), while smaller values will allow the optimisation to focus more on the individual embeddings and put less emphasis on aligning the embeddings with each other.\n",
    "        n_epochs=300,\n",
    "        random_state=None,  # calculate aligned UMAPs with different random seeds\n",
    "        verbose=False,\n",
    "        n_components=2,\n",
    "    ).fit(embeddings, relations=constant_relations)\n",
    "    list_of_alignments.append(_neighbors_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the distance for each alignment\n",
    "distances = []\n",
    "for idx, val in enumerate(list_of_alignments):\n",
    "    _distance = calculate_distance(val)\n",
    "    distances.append(_distance)\n",
    "\n",
    "# calculate the mean of the distances\n",
    "dist_mean_2D = np.mean(distances, axis=0)\n",
    "# calculate the variance of the distances\n",
    "dist_variance_2D = np.var(distances, axis=0)\n",
    "# calculate the standard deviation of the distances\n",
    "dist_std_2D = np.std(distances, axis=0)\n",
    "# calculate the coefficient of variation of the distances\n",
    "dist_cv_2D = dist_std_2D / dist_mean_2D"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the 2D embeddings and 2D, 10D distances (along with other columns) to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'n_seeds' (int)\n"
     ]
    }
   ],
   "source": [
    "# save aligned umap embeddings to csv\n",
    "merged[\"JointUMAP_uninf_1\"] = neighbors_mapper.embeddings_[0].T[0]\n",
    "merged[\"JointUMAP_uninf_2\"] = neighbors_mapper.embeddings_[0].T[1]\n",
    "merged[\"JointUMAP_inf_1\"] = neighbors_mapper.embeddings_[1].T[0]\n",
    "merged[\"JointUMAP_inf_2\"] = neighbors_mapper.embeddings_[1].T[1]\n",
    "\n",
    "# save 2D distances to csv\n",
    "merged[f\"2d_mean_distance_traveled ({n_seeds} bootstraps)\"] = dist_mean_2D\n",
    "merged[f\"2d_coefficient_variance_distance_traveled ({n_seeds} bootstraps)\"] = dist_cv_2D\n",
    "\n",
    "# save 10D distances to csv\n",
    "merged[f\"10d_mean_distance_traveled ({n_seeds} bootstraps)\"] = dist_mean_10D\n",
    "merged[f\"10d_coefficient_variance_distance_traveled ({n_seeds} bootstraps)\"] = dist_cv_10D\n",
    "\n",
    "save_path = output_folder / f\"{fig5_timestamp}_AlignedUMAP_embeddings_and_distances.csv\"\n",
    "merged.to_csv(save_path, index=False)\n",
    "\n",
    "# save the number of seeds used to calculate the distances, needed to for the subsequent notebooks to find the correct file\n",
    "%store n_seeds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OrgIP_zenodo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
