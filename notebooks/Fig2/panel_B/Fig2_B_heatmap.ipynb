{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig. 2 panel B heatmap\n",
    "\n",
    "This notebook:\n",
    "- Loads an enrichment table and preprocess it. The preprocessed results are used in subsequent notebooks\n",
    "- Compute the distance between each pair of PGs\n",
    "- Plots the distance as a heatmap.   \n",
    "\n",
    "Notes:  \n",
    "- All distance calculations are done prior to plotting, and it takes ~ 2 minutes (can remove superfluous metrics to make it faster)  \n",
    "- Once the calculations are done, plotting can be repeatedly executed to explore different plotting parameters.  \n",
    "- Clustering the rows/columns is part of the plotting process, and it takes ~ 3 minutes  \n",
    "- Rendering the heatmap takes ~ 2 minutes  \n",
    "- result files are written to a folder named ``output``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, itertools\n",
    "from pathlib import Path\n",
    "import bokeh.palettes\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "import scipy\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_theme(color_codes=True)\n",
    "plt.rcParams[\"pdf.fonttype\"] = 42\n",
    "\n",
    "script_path = Path.cwd().parent.parent.parent / \"script\"\n",
    "data_path = Path.cwd().parent.parent.parent / \"data\"\n",
    "sys.path.append(str(script_path))\n",
    "from pyseus.plotting import plotly_umap as pu\n",
    "from utils.label_processing import attach_annotations\n",
    "\n",
    "outputdir = f\"output\"\n",
    "if not os.path.exists(outputdir):\n",
    "    os.makedirs(outputdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the enrichment table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 2023-10-21-imp5-for-figures\n"
     ]
    }
   ],
   "source": [
    "%store -r timestamp\n",
    "print(f\"Timestamp: {timestamp}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define files to load\n",
    "enrichment_dir = Path.cwd().parent.parent / \"enrichment\"\n",
    "enrichment_csv_path = enrichment_dir / \"output\" / \"enrichment_and_volcano_tables\" / f\"{timestamp}_enrichment_table_NOC_prop.csv\"\n",
    "\n",
    "try:\n",
    "    # load the file\n",
    "    enrichments = pd.read_csv(enrichment_csv_path, header=[0, 1], index_col=0)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File {enrichment_csv_path} not found.\\nPlease run the enrichment analysis first or specify the correct timestamp, current value is {timestamp}\")\n",
    "except pd.errors.ParserError:\n",
    "    print(f\"There was an error parsing the CSV file at {enrichment_csv_path}.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach canonical gene names\n",
    "gene_name_csv = data_path / \"external\" / \"canonical_names_and_Itzhak_data.csv\"\n",
    "\n",
    "lookup_table = pd.read_csv(gene_name_csv)\n",
    "to_df = enrichments[\"metadata\"].copy()\n",
    "list_of_cols_to_add = reversed([\"Gene_name_canonical\"])\n",
    "for c in list_of_cols_to_add:\n",
    "    new_col_data = attach_annotations(from_df=lookup_table, to_df=to_df, anno_col=c, from_on=\"Majority protein IDs\", to_on=\"Majority protein IDs\")\n",
    "    enrichments[(\"metadata\", \"Gene_name_canonical\")] = new_col_data\n",
    "\n",
    "# attach ground truth\n",
    "ground_truth_csv = data_path / \"external\" / \"curated_ground_truth_v9.0.csv\"\n",
    "\n",
    "lookup_table = pd.read_csv(ground_truth_csv)\n",
    "to_df = enrichments[\"metadata\"].copy()\n",
    "list_of_cols_to_add = reversed([\"compartment\"])\n",
    "for c in list_of_cols_to_add:\n",
    "    new_col_data = attach_annotations(from_df=lookup_table, to_df=to_df, anno_col=c, from_on=\"gene_name_canonical\", to_on=\"Gene_name_canonical\")\n",
    "    enrichments[(\"metadata\", \"curated_ground_truth_v9.0\")] = new_col_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample exclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non-relavent samples from the mass spectrometry master file\n",
    "# remove infected IPs from the mass spectrometry master file as it shouldn't be used in calculating the reference UMAP\n",
    "cols = list(enrichments[\"sample\"])\n",
    "meta_cols = list(enrichments[\"metadata\"])\n",
    "samples = [\n",
    "    x for x in cols\n",
    "    if \"WT\" not in x # remove WTs as they represent background binding\n",
    "    and \"harsh\" not in x # remove samples tagged with \"harsh\"\n",
    "    and \"unsorted\" not in x # remove unsorted samples\n",
    "    and \"Infected\" not in x # remove the infected samples (these are present because they are processed together in the same MaxQuant run)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of selected samples is 71\n",
      "the selected samples are ['01-CAPRIN1', '02-ATG101', '02-COPE', '02-DCP1A', '02-GOLGA2', '02-RICTOR', '03-EXOC2', '03-HSP90AA', '03-HSPA1B', '03-SEC23A', '05-CAV1', '05-EDC4', '05-NCLN', '06-ATP6V1B2', '06-CCDC47', '06-CSNK2A1', '06-CSNK2A2', '06-YWHAB', '07-AP4B1', '07-CLTA', '07-COG8', '07-RAPTOR', '09-ATG101', '09-EDC4', '09-HSP90AA1', '09-PEX3', '09-PSMB7', '09-TOMM20', '10-AP2B1', '10-EXOC2', '10-RTN4', '10-TOMM20', '10-VPS35', '11-CEP350', '11-EEA1', '11-GPR107', '11-SEC31A', '12-ACTB', '12-G3BP1', '12-LAMP1', '12-PNPLA2', '12-RTN4', '12-SEC61B', '12-TOMM20', '12-YWHAQ', '13-GOLGA2', '13-RAB11A', '13-RAB14', '13-RAB1A', '13-RAB7A', '14-COPE', '14-GOLGA2', '14-RAB11A', '14-RAB14', '14-RAB1A', '14-RAB7A', '15-G3BP1', '15-GOLGA2', '15-LAMP1', '15-MAP1LC3B', '15-SEC61B', '15-TOMM20', '17-ATP1B3', '17-CAPRIN1', '17-G3BP1', '17-MAP1LC3B', '17-RPL36', '17-SLC30A2', 'NOC_cytosol', 'NOC_nuclear', 'NOC_organelle']\n"
     ]
    }
   ],
   "source": [
    "# check the samples\n",
    "print(f\"the number of selected samples is {len(samples)}\")\n",
    "print(f\"the selected samples are {sorted(samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non-informative IPs from the mass spectrometry master file; these correspond to IPs for soluble targets that peripherally bind membranes\n",
    "# these IPs were not successful at pulling down membrane compartments, and were therefore removed from subsequent analyses\n",
    "to_drop = [\"06-ATP6V1B2\",\"06-CSNK2A1\", \"06-CSNK2A2\", \"07-AP4B1\", '02-RICTOR', \"07-RAPTOR\", \"10-AP2B1\", \"12-PNPLA2\", \"03-EXOC2\", \"10-EXOC2\"]\n",
    "selected_samples = [x for x in samples if x not in to_drop] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of selected samples is 61\n",
      "the selected samples are ['01-CAPRIN1', '02-ATG101', '02-COPE', '02-DCP1A', '02-GOLGA2', '03-HSP90AA', '03-HSPA1B', '03-SEC23A', '05-CAV1', '05-EDC4', '05-NCLN', '06-CCDC47', '06-YWHAB', '07-CLTA', '07-COG8', '09-ATG101', '09-EDC4', '09-HSP90AA1', '09-PEX3', '09-PSMB7', '09-TOMM20', '10-RTN4', '10-TOMM20', '10-VPS35', '11-CEP350', '11-EEA1', '11-GPR107', '11-SEC31A', '12-ACTB', '12-G3BP1', '12-LAMP1', '12-RTN4', '12-SEC61B', '12-TOMM20', '12-YWHAQ', '13-GOLGA2', '13-RAB11A', '13-RAB14', '13-RAB1A', '13-RAB7A', '14-COPE', '14-GOLGA2', '14-RAB11A', '14-RAB14', '14-RAB1A', '14-RAB7A', '15-G3BP1', '15-GOLGA2', '15-LAMP1', '15-MAP1LC3B', '15-SEC61B', '15-TOMM20', '17-ATP1B3', '17-CAPRIN1', '17-G3BP1', '17-MAP1LC3B', '17-RPL36', '17-SLC30A2', 'NOC_cytosol', 'NOC_nuclear', 'NOC_organelle']\n"
     ]
    }
   ],
   "source": [
    "# check the selected samples after manual sample removal\n",
    "print(f\"the number of selected samples is {len(selected_samples)}\")\n",
    "print(f\"the selected samples are {sorted(selected_samples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dimensions of the data table are (8541, 61)\n"
     ]
    }
   ],
   "source": [
    "# finalize the table\n",
    "enrich_table = enrichments.droplevel(0, axis=1)[meta_cols + selected_samples].copy()\n",
    "# normalization and UMAP algorithm are not compatible with any NaN values, so drop them\n",
    "enrich_table = enrich_table.dropna(subset=selected_samples)\n",
    "quants = enrich_table[selected_samples].copy()\n",
    "print(f\"the dimensions of the data table are {quants.shape}\")\n",
    "# scale the data\n",
    "scaled = pu.scale_table(matrix=quants, method=\"standard\")\n",
    "\n",
    "# save the scaled data\n",
    "scaled_path = os.path.join(outputdir, f\"{timestamp}_scaled_data.csv\")\n",
    "scaled_df = pd.DataFrame(scaled, index=enrich_table[\"Gene_name_canonical\"], columns=enrich_table.iloc[:,5:].columns)\n",
    "scaled_df.to_csv(scaled_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate distance matrices\n",
    "this section calculates distance using all possible distance metrics, and takes about 2 minutes  \n",
    "feel free to remove some of the metrics from the method_list to speed up calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to compute distance matrices\n",
    "def calc_dist_mat(data, method=\"euclidean\"):\n",
    "    if method not in [\"minkowski\", \"seuclidean\", \"mahalanobis\"]:\n",
    "        dist_mat = scipy.spatial.distance.pdist(data, method)\n",
    "    elif method == \"minkowski\":\n",
    "        dist_mat = scipy.spatial.distance.pdist(data, method, p=2.0)\n",
    "    elif method == \"seuclidean\":\n",
    "        dist_mat = scipy.spatial.distance.pdist(data, method, V=None)\n",
    "    elif method == \"mahalanobis\":\n",
    "        dist_mat = scipy.spatial.distance.pdist(data, method, VI=None)\n",
    "    # return square form of distance matrix\n",
    "    return scipy.spatial.distance.squareform(dist_mat)\n",
    "\n",
    "\n",
    "def calc_all_dist_mat(\n",
    "    data, method_list=[\"canberra\", \"correlation\", \"cosine\"]\n",
    "):  # other possible values are 'braycurtis', 'chebyshev', 'cityblock',  'dice', 'euclidean', 'hamming', 'jaccard', 'jensenshannon', 'kulczynski1', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule'\n",
    "    dist_mat_dict = {}\n",
    "    for method in method_list:\n",
    "        dist_mat_dict[method] = calc_dist_mat(data, method)\n",
    "    return dist_mat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute distance matrices\n",
    "distMats = calc_all_dist_mat(data=scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot_dfs(distMat, merged_umap_table, annot_col):\n",
    "    '''\n",
    "    This function takes in one distrance matrix and the merged umap table and returns two dataframes for plotting\n",
    "    subsets the data for plotting, retain only those with labels\n",
    "    returns:\n",
    "    df_plot: distance matrix dataframe for plotting\n",
    "    df_annots_plot: metadata dataframe for color mapping   \n",
    "    '''\n",
    "    # dedup the table based on genes\n",
    "    merged_umap_table_noDup = merged_umap_table.drop_duplicates(subset='Gene_name_canonical', keep='first')\n",
    "\n",
    "    # construct metadata dataframe\n",
    "    cols_to_exclude = enrichments[\"sample\"].columns.to_list()\n",
    "    df_annots = merged_umap_table_noDup[[col for col in merged_umap_table_noDup.columns if col not in cols_to_exclude]]\n",
    "\n",
    "    #df_annots[\"organelle_ML3.0\"] = df_annots[\"organelle_ML3.0\"].fillna(\"undef\")\n",
    "    df_annots[annot_col] = df_annots[annot_col].fillna(\"undef\")\n",
    "\n",
    "    # construct distance matrix dataframe\n",
    "    # subset the distance matrix to only include the genes in the deduped matrix\n",
    "    df_dist = distMat[merged_umap_table_noDup.index,:][:,merged_umap_table_noDup.index]\n",
    "    df_dist = pd.DataFrame(df_dist, index=merged_umap_table_noDup[\"Gene_name_canonical\"], columns=merged_umap_table_noDup[\"Gene_name_canonical\"])\n",
    "\n",
    "    # subset the data for plotting, retain only those with labels\n",
    "    idx = df_annots[annot_col] != \"undef\"\n",
    "    df_annots_plot = df_annots[idx].copy()\n",
    "    df_plot = df_dist.loc[df_annots_plot[\"Gene_name_canonical\"]]\n",
    "    df_plot = df_plot[df_annots_plot[\"Gene_name_canonical\"]]\n",
    "\n",
    "    # create color palette\n",
    "    orgnaelle_uni = list(set(df_annots_plot[annot_col]))\n",
    "    orgnaelle_uni.sort() # consistent legend\n",
    "    # Get the Category20 colors and create an iterator to cycle through them\n",
    "    category20_colors = bokeh.palettes.Category20[20]\n",
    "    color_iterator = itertools.cycle(category20_colors)\n",
    "    # Create a list to store your 27 colors\n",
    "    colors = []\n",
    "    # Append colors to the list for each category\n",
    "    for _ in range(len(orgnaelle_uni)):\n",
    "        colors.append(next(color_iterator))\n",
    "    orgnaelle_color_pal = colors # 27 colors with expert annotation\n",
    "\n",
    "    Organelle2color = {}\n",
    "    for idx, ogranelle in enumerate(orgnaelle_uni):\n",
    "        Organelle2color[ogranelle] = orgnaelle_color_pal[idx]\n",
    "\n",
    "    # replace orgranelle names with colors\n",
    "    df_annots_plot[\"color\"] = df_annots_plot[annot_col].apply(lambda x: Organelle2color[x])\n",
    "    #\n",
    "    df_annots_plot.set_index(\"Gene_name_canonical\", inplace=True)\n",
    "\n",
    "    return df_plot, df_annots_plot, Organelle2color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the distance heatmap\n",
    "Once the prep work section (above) has been executed once, this section can be repeatly executed to explore plotting options. It is advied to execute the whole plotting section each time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define heatmap parameters (aesthetics are in a later cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance metric used to calculate the protein pair-wise distance (using their enrichment vectors). This distance is shown in the heatmap\n",
    "distance_metric1 = \"correlation\"\n",
    "# row/column clusetering parameters\n",
    "distance_metric2 = \"cosine\"  # distance mertic used for clustering, **NOT** for calculating distance using enrichment table\n",
    "linkage_method = \"average\"  # linkage method used for clustering, \"averge\" tends to work better than 'complete' for our data\n",
    "\n",
    "# name of the annotation column, the info is shown in the sidebar of the heatmap\n",
    "# note that PGs with nan, undef labels will be removed\n",
    "annotation_col = \"curated_ground_truth_v9.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More prep work (adjusting dataframes and clustering rows/columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the dataframes for plotting\n",
    "df_plot, df_annots_plot, Organelle2color = make_plot_dfs(distMat=distMats[distance_metric1], merged_umap_table=enrich_table, annot_col=annotation_col)\n",
    "\n",
    "# add numeric index to the dataframes\n",
    "df_annots_plot.index = pd.RangeIndex(len(df_annots_plot.index))\n",
    "df_plot.index = pd.RangeIndex(len(df_plot.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\duo.peng\\AppData\\Local\\Temp\\ipykernel_29912\\1857863584.py:4: ClusterWarning:\n",
      "\n",
      "scipy.cluster: The symmetric non-negative hollow observation matrix looks suspiciously like an uncondensed distance matrix\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cluster rows and columns (takes a few minutes to run)\n",
    "\n",
    "# compute distance matrix for clustering\n",
    "distance_matrix = sch.linkage(df_plot, method=linkage_method, metric=distance_metric2)  # Hierarchical clustering\n",
    "\n",
    "# Reorder rows and columns based on clustering results\n",
    "row_order = sch.dendrogram(distance_matrix, no_plot=True, orientation='bottom')['leaves']\n",
    "col_order = sch.dendrogram(distance_matrix, no_plot=True, orientation='top')['leaves']\n",
    "\n",
    "# apply the final order\n",
    "data_reordered = df_plot.iloc[row_order, col_order]\n",
    "\n",
    "# make the column index name the same as that of the row index\n",
    "# make the column names the same as the row index, else the row colors won't work\n",
    "gene_names = data_reordered.columns\n",
    "data_reordered.index.name = data_reordered.columns.name \n",
    "data_reordered.columns = data_reordered.index \n",
    "\n",
    "# row and column colors\n",
    "df_annots_plot_sorted_by_row = df_annots_plot.iloc[row_order] # sort the annotation dataframe by the row order\n",
    "clut = Organelle2color\n",
    "row_colors = df_annots_plot_sorted_by_row[annotation_col].map(clut)\n",
    "\n",
    "df_annots_plot_sorted_by_col = df_annots_plot.iloc[col_order] # sort the annotation dataframe by the col order\n",
    "clut = Organelle2color\n",
    "col_colors = df_annots_plot_sorted_by_col[annotation_col].map(clut)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aesthetics here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust contrast, following Manu's suggestions\n",
    "data_reordered = data_reordered.where(data_reordered > 0.4, 0.4)\n",
    "data_reordered = data_reordered.where(data_reordered < 0.9, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color palette\n",
    "pal = \"Blues\"  # For other options, see this page: https://matplotlib.org/stable/users/explain/colors/colormaps.html\n",
    "reverse_pal = True  # Whether to **reverse** the color palette\n",
    "\n",
    "if reverse_pal:  # reverse the color palette if boolean is True\n",
    "    pal = pal + \"_r\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the sns command is in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the heatmap with seaborn (using precomputed clusters. Using seaborn to cluster rows/cols takes forever)\n",
    "# takes 1-2 minutes to run\n",
    "plt.clf()\n",
    "sns.set(font_scale=2)\n",
    "g = sns.clustermap(\n",
    "    data=data_reordered,\n",
    "    cmap=sns.color_palette(pal, as_cmap=True), row_colors=row_colors, col_colors=col_colors,\n",
    "    row_cluster=False, col_cluster=False,\n",
    "    colors_ratio=(0.02, 0.02),  # width of color bar\n",
    "    cbar_pos=(0.18, 0.9, 0.5, 0.03),  # color bar location coordinates in this format (left, bottom, width, height),\n",
    "    # cbar_pos=None,\n",
    "    cbar_kws={\"orientation\": \"horizontal\", \"label\": f\"distance\", \"extend\": \"neither\"},\n",
    "    robust=True, figsize=(24, 22), xticklabels=False, yticklabels=False,\n",
    ")\n",
    "\n",
    "g.fig.suptitle(\n",
    "    f\"Pairwise distance between proteins in the enrichment space\\n(distance metric: {distance_metric1})\\n(row/column clustering linkage method: {linkage_method} , clustering distance metric:{distance_metric2})\",\n",
    "    fontsize=35, y=1.00,\n",
    ")\n",
    "g.ax_heatmap.set_xlabel(\"\")\n",
    "g.ax_heatmap.set_ylabel(\"\")\n",
    "\n",
    "# row/col colors legend\n",
    "clut1 = Organelle2color\n",
    "handles = [Patch(facecolor=clut1[name]) for name in clut1]\n",
    "col_legend1 = plt.legend(\n",
    "    handles, clut1,\n",
    "    title=\"Annotation\",\n",
    "    bbox_to_anchor=(0.9, 0.79), bbox_transform=plt.gcf().transFigure,\n",
    "    loc=\"upper left\", fontsize=20,\n",
    ")\n",
    "plt.gca().add_artist(col_legend1)\n",
    "\n",
    "plot_name = f\"shownDist={distance_metric1}_ClusterDist={distance_metric2}_Linkage={linkage_method}\"\n",
    "plt.savefig(f\"{outputdir}/{plot_name}.png\", bbox_inches=\"tight\", format=\"png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive htmls\n",
    "produce interactive versions of the heatmap (using plotly)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: plot interactive html in 4 chunks\n",
    "\n",
    "# load required library for this part\n",
    "import dash_bio\n",
    "\n",
    "\n",
    "# define a function to split data into n chunks (to avoid producing a huge html file that won't open)\n",
    "def split_range_into_chunks(start, end, num_chunks):\n",
    "    \"\"\"Splits a range into num_chunks chunks and returns the start and end of each chunk.\"\"\"\n",
    "    chunk_size, remainder = divmod(end - start, num_chunks)\n",
    "    chunks = []\n",
    "    current_start = start\n",
    "    for i in range(num_chunks):\n",
    "        # If there's remainder, add one more to the chunk size\n",
    "        current_end = current_start + chunk_size + (1 if i < remainder else 0)\n",
    "        chunks.append((current_start, current_end - 1))  # Subtract 1 to get the last item in the current range\n",
    "        current_start = current_end\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# split the data into n chunks \n",
    "chunks = split_range_into_chunks(0, data_reordered.shape[0] - 1, num_chunks=1)\n",
    "\n",
    "# plot the heatmap with plotly an save as an html file\n",
    "plot_name = f\"shownDist={distance_metric1}_ClusterDist={distance_metric2}_Linkage={linkage_method}\"\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    data = data_reordered.iloc[chunk[0] : chunk[1], chunk[0] : chunk[1]]\n",
    "    clustergram = dash_bio.Clustergram(\n",
    "        data=data.iloc[::-1, :],  # reverse the order of the rows, b/c for some reason the order is reversed in the plotly heatmap\n",
    "        column_colors=col_colors.tolist()[chunk[0] : chunk[1]],\n",
    "        row_colors=row_colors.tolist()[chunk[0] : chunk[1]][::-1],  # reverse the order of the rows\n",
    "        column_labels=gene_names.tolist()[chunk[0] : chunk[1]],  # hover x labels\n",
    "        row_labels=gene_names.tolist()[chunk[0] : chunk[1]][::-1],  # hover y labels # reverse the order of the rows\n",
    "        height=1000, width=1200,\n",
    "        cluster=False,\n",
    "        color_map=pal,\n",
    "        hidden_labels=[\"row\", \"col\"],\n",
    "        # generate_curves_dict= True,\n",
    "        # return_computed_traces= True\n",
    "    )\n",
    "    pio.write_html(\n",
    "        clustergram,\n",
    "        file=os.path.join(outputdir, f\"{plot_name}_chunk{idx+1}.html\"),\n",
    "        auto_open=False,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orgIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
