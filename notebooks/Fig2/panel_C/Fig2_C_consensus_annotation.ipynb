{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig. 2 panel C protein-level concensus annotation\n",
    "\n",
    "This notebook generates two sets of annotations:\n",
    "- Graph-based_localization_annotation  \n",
    "  For each protein, this is the most common annotation in the neighbor annotation \n",
    "- consensus_graph_annnotation\n",
    "  Based on the graph-based localization annotation, for proteins where the graph-based annotation is unclassified, use the cluster annotation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\duo.peng\\Documents\\Organelle_IP_figures_14-3-3\\notebooks\\Fig2\\panel_C\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import anndata as ad\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "import umap\n",
    "import umap.plot\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "script_path = Path.cwd().parent.parent.parent / \"script\"\n",
    "data_path = Path.cwd().parent.parent.parent / \"data\"\n",
    "sys.path.append(str(script_path))\n",
    "from external import clustering_workflows\n",
    "from utils.Jaccard_coefficient import *\n",
    "from utils.label_processing import attach_annotations\n",
    "\n",
    "save_path = Path.cwd() / \"output\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the enrichment table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 2024-07-14\n"
     ]
    }
   ],
   "source": [
    "%store -r timestamp\n",
    "print(f\"Timestamp: {timestamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define files to load\n",
    "enrichment_dir = Path.cwd().parent.parent / \"enrichment\"\n",
    "enrichment_csv_path = enrichment_dir / \"output\" / \"enrichment_and_volcano_tables\" / f'{timestamp}_enrichment_table_NOC_prop.csv'\n",
    "\n",
    "try:\n",
    "    # load the file\n",
    "    enrichments = pd.read_csv(enrichment_csv_path, header=[0, 1], index_col=0)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File {enrichment_csv_path} not found.\\nPlease run the enrichment analysis first or specify the correct timestamp, current value is {timestamp}\")\n",
    "except pd.errors.ParserError:\n",
    "    print(f\"There was an error parsing the CSV file at {enrichment_csv_path}.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the enrichment metadata columns\n",
    "# enrichments[\"metadata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the sample columns\n",
    "# enrichments[\"sample\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach canonical gene names\n",
    "gene_name_csv = data_path / \"external\" / \"canonical_names_and_Itzhak_data.csv\"\n",
    "\n",
    "lookup_table = pd.read_csv(gene_name_csv)\n",
    "to_df = enrichments[\"metadata\"].copy()\n",
    "list_of_cols_to_add = reversed([\"Gene_name_canonical\"])\n",
    "for c in list_of_cols_to_add:\n",
    "    new_col_data = attach_annotations(from_df=lookup_table, to_df=to_df, anno_col=c, from_on=\"Majority protein IDs\", to_on=\"Majority protein IDs\")\n",
    "    enrichments[(\"metadata\", \"Gene_name_canonical\")] = new_col_data\n",
    "\n",
    "# attach ground truth\n",
    "ground_truth_csv = data_path / \"external\" / \"curated_ground_truth_v9.0.csv\"\n",
    "\n",
    "lookup_table = pd.read_csv(ground_truth_csv)\n",
    "to_df = enrichments[\"metadata\"].copy()\n",
    "list_of_cols_to_add = reversed([\"compartment\"])\n",
    "for c in list_of_cols_to_add:\n",
    "    new_col_data = attach_annotations(from_df=lookup_table, to_df=to_df, anno_col=c, from_on=\"gene_name_canonical\", to_on=\"Gene_name_canonical\")\n",
    "    enrichments[(\"metadata\", \"curated_ground_truth_v9.0\")] = new_col_data\n",
    "\n",
    "# attach labels\n",
    "labels_csv = data_path / \"labels\" / \"cluster_annotation_Dec6.csv\"\n",
    "\n",
    "lookup_table = pd.read_csv(labels_csv)\n",
    "to_df = enrichments[\"metadata\"].copy()\n",
    "list_of_cols_to_add = reversed([\"cluster_annotation\"])\n",
    "for c in list_of_cols_to_add:\n",
    "    new_col_data = attach_annotations(from_df=lookup_table, to_df=to_df, anno_col=c, from_on=\"Majority protein IDs\", to_on=\"Majority protein IDs\")\n",
    "    enrichments[(\"metadata\", \"cluster_annotation\")] = new_col_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample selection for the Leiden and the UMAP algorithms, NOTE: manual sample removal is NOT in this cell\n",
    "\n",
    "# there are some superfluous samples in this table as well as WTs\n",
    "# these dont help too much in separating organelles so not counting them\n",
    "# we also remove the infected samples here as those shouldn't be used in calculating the reference UMAP\n",
    "cols = list(enrichments[\"sample\"])\n",
    "meta_cols = list(enrichments[\"metadata\"])\n",
    "samples = [\n",
    "    x for x in cols\n",
    "    if \"WT\" not in x\n",
    "    and \"harsh\" not in x\n",
    "    and \"unsorted\" not in x\n",
    "    and \"Infected\" not in x\n",
    "]\n",
    "\n",
    "# next, we remove additional samples using bait names\n",
    "genes = [x.split(\"-\")[1] if \"-\" in x else x for x in samples]\n",
    "sample_table = pd.DataFrame()\n",
    "sample_table[\"samples\"] = samples\n",
    "sample_table[\"bait\"] = genes\n",
    "\n",
    "bait_drop_list = [\"EXOC2\"]  # here we are just removing EXOC2\n",
    "selected_samples = []\n",
    "for index, row in sample_table.iterrows():\n",
    "    if row[\"bait\"] not in bait_drop_list:\n",
    "        selected_samples.append(row[\"samples\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of selected samples is 68\n",
      "the selected samples are ['01-CAPRIN1', '02-ATG101', '02-COPE', '02-DCP1A', '02-GOLGA2', '02-RICTOR', '03-HSP90AA', '03-HSPA1B', '03-SEC23A', '05-CAV1', '05-EDC4', '05-NCLN', '06-ATP6V1B2', '06-CCDC47', '06-CSNK2A1', '06-CSNK2A2', '06-YWHAB', '07-AP4B1', '07-CLTA', '07-COG8', '07-RAPTOR', '09-ATG101', '09-EDC4', '09-HSP90AA1', '09-PEX3', '09-PSMB7', '09-TOMM20', '10-AP2B1', '10-RTN4', '10-TOMM20', '10-VPS35', '11-CEP350', '11-EEA1', '11-GPR107', '11-SEC31A', '12-ACTB', '12-G3BP1', '12-LAMP1', '12-PNPLA2', '12-RTN4', '12-SEC61B', '12-TOMM20', '13-GOLGA2', '13-RAB11A', '13-RAB14', '13-RAB1A', '13-RAB7A', '14-COPE', '14-GOLGA2', '14-RAB11A', '14-RAB14', '14-RAB1A', '14-RAB7A', '15-G3BP1', '15-GOLGA2', '15-LAMP1', '15-MAP1LC3B', '15-SEC61B', '15-TOMM20', '17-ATP1B3', '17-CAPRIN1', '17-G3BP1', '17-MAP1LC3B', '17-RPL36', '17-SLC30A2', 'NOC_cytosol', 'NOC_nuclear', 'NOC_organelle']\n"
     ]
    }
   ],
   "source": [
    "# check the selected samples\n",
    "print(f\"the number of selected samples is {len(selected_samples)}\")\n",
    "print(f\"the selected samples are {sorted(selected_samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually drop a few samples \n",
    "to_drop = [\"02-EXOC2\",\"06-ATP6V1B2\",\"06-CSNK2A1\", \"06-CSNK2A2\", \"07-AP4B1\", '02-RICTOR', \"07-RAPTOR\", \"10-AP2B1\", \"12-PNPLA2\"]  # for example: to_drop = [\"09-HSP90AA1\", \"09-PSMB7\"]\n",
    "selected_samples = [x for x in selected_samples if x not in to_drop]  # update the variable: selected_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of selected samples is 60\n",
      "the selected samples are ['01-CAPRIN1', '02-ATG101', '02-COPE', '02-DCP1A', '02-GOLGA2', '03-HSP90AA', '03-HSPA1B', '03-SEC23A', '05-CAV1', '05-EDC4', '05-NCLN', '06-CCDC47', '06-YWHAB', '07-CLTA', '07-COG8', '09-ATG101', '09-EDC4', '09-HSP90AA1', '09-PEX3', '09-PSMB7', '09-TOMM20', '10-RTN4', '10-TOMM20', '10-VPS35', '11-CEP350', '11-EEA1', '11-GPR107', '11-SEC31A', '12-ACTB', '12-G3BP1', '12-LAMP1', '12-RTN4', '12-SEC61B', '12-TOMM20', '13-GOLGA2', '13-RAB11A', '13-RAB14', '13-RAB1A', '13-RAB7A', '14-COPE', '14-GOLGA2', '14-RAB11A', '14-RAB14', '14-RAB1A', '14-RAB7A', '15-G3BP1', '15-GOLGA2', '15-LAMP1', '15-MAP1LC3B', '15-SEC61B', '15-TOMM20', '17-ATP1B3', '17-CAPRIN1', '17-G3BP1', '17-MAP1LC3B', '17-RPL36', '17-SLC30A2', 'NOC_cytosol', 'NOC_nuclear', 'NOC_organelle']\n"
     ]
    }
   ],
   "source": [
    "# check the selected samples after manual sample removal\n",
    "print(f\"the number of selected samples is {len(selected_samples)}\")\n",
    "print(f\"the selected samples are {sorted(selected_samples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dimensions of the data table saved for UMAP are (8541, 60)\n"
     ]
    }
   ],
   "source": [
    "# save a copy of the tables for UMAP\n",
    "\n",
    "umap_table = enrichments.droplevel(0, axis=1)[meta_cols + selected_samples].copy()\n",
    "# normalization and UMAP algorithm are not compatible with any NaN values, so drop them\n",
    "umap_table = umap_table.dropna(subset=selected_samples)\n",
    "quants = umap_table[selected_samples].copy()\n",
    "print(f\"the dimensions of the data table saved for UMAP are {quants.shape}\")\n",
    "\n",
    "quants.to_csv(save_path / f\"{timestamp}_quants.csv\")\n",
    "umap_table.to_csv(save_path / f\"{timestamp}_umap_table.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert data into anndata format \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\duo.peng\\AppData\\Roaming\\Python\\Python310\\site-packages\\anndata\\_core\\anndata.py:120: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n",
      "C:\\Users\\duo.peng\\AppData\\Roaming\\Python\\Python310\\site-packages\\anndata\\_core\\anndata.py:1228: FutureWarning: The `inplace` parameter in pandas.Categorical.reorder_categories is deprecated and will be removed in a future version. Reordering categories will always return a new Categorical object.\n",
      "  c.reorder_categories(natsorted(c.categories), inplace=True)\n",
      "... storing 'Gene_name_canonical' as categorical\n",
      "C:\\Users\\duo.peng\\AppData\\Roaming\\Python\\Python310\\site-packages\\anndata\\_core\\anndata.py:1228: FutureWarning: The `inplace` parameter in pandas.Categorical.reorder_categories is deprecated and will be removed in a future version. Reordering categories will always return a new Categorical object.\n",
      "  c.reorder_categories(natsorted(c.categories), inplace=True)\n",
      "... storing 'curated_ground_truth_v9.0' as categorical\n",
      "C:\\Users\\duo.peng\\AppData\\Roaming\\Python\\Python310\\site-packages\\anndata\\_core\\anndata.py:1228: FutureWarning: The `inplace` parameter in pandas.Categorical.reorder_categories is deprecated and will be removed in a future version. Reordering categories will always return a new Categorical object.\n",
      "  c.reorder_categories(natsorted(c.categories), inplace=True)\n",
      "... storing 'cluster_annotation' as categorical\n"
     ]
    }
   ],
   "source": [
    "# generating AnnData\n",
    "selected = enrichments['sample'][selected_samples].copy()\n",
    "adata = ad.AnnData(selected, dtype=np.float32)\n",
    "\n",
    "adata.var_names = selected.columns.to_list()\n",
    "adata.obs_names = enrichments['metadata'][\"Protein IDs\"].to_list()\n",
    "adata.obs[\"Protein IDs\"] = enrichments['metadata'][\"Protein IDs\"].to_list()\n",
    "adata.obs[\"Majority protein IDs\"] = enrichments['metadata'][\"Majority protein IDs\"].to_list()\n",
    "adata.obs[\"Gene_name_canonical\"] = enrichments['metadata'][\"Gene_name_canonical\"].to_list()\n",
    "adata.obs[\"curated_ground_truth_v9.0\"] = enrichments['metadata'][\"curated_ground_truth_v9.0\"].to_list()\n",
    "adata.obs[\"cluster_annotation\"] = enrichments['metadata'][\"cluster_annotation\"].to_list()\n",
    "\n",
    "adata.write_h5ad(save_path / f\"adata_{timestamp}.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute knn graph (and save a copy for later use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a clusteringworkflow class (to use the part of workflow that computes the nearest neighbor graph)\n",
    "kNN_obj = clustering_workflows.ClusteringWorkflow(adata=copy.deepcopy(adata))\n",
    "# preprocessing\n",
    "kNN_obj.preprocess(n_pcs=None)\n",
    "# compute nearest neighbor graph\n",
    "kNN_obj.calculate_neighbors(n_pcs=None, n_neighbors=20)\n",
    "adata = kNN_obj.adata\n",
    "# save a copy of the adata object that contains the kNN graph\n",
    "knn_adata_path = save_path / f\"adata_kNN_{timestamp}.h5ad\"\n",
    "adata.write(knn_adata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 8541 × 60\n",
       "    obs: 'Protein IDs', 'Majority protein IDs', 'Gene_name_canonical', 'curated_ground_truth_v9.0', 'cluster_annotation'\n",
       "    var: 'mean', 'std'\n",
       "    uns: 'neighbors'\n",
       "    obsp: 'distances', 'connectivities'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kNN_obj.adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate protein-level consensus annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_majority_ids = adata.obs[\"Majority protein IDs\"].to_list()\n",
    "all_genes = adata.obs[\"Gene_name_canonical\"].to_list()\n",
    "\n",
    "annot_df = pd.DataFrame(\n",
    "    list(zip(\n",
    "            adata.obs[\"Majority protein IDs\"].to_list(),\n",
    "            adata.obs[\"Gene_name_canonical\"].to_list(),\n",
    "            adata.obs[\"cluster_annotation\"].to_list(),\n",
    "        )),\n",
    "    columns=[\"Majority protein IDs\", \"Gene_name_canonical\", \"cluster_annotation\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed9d871b29544658bed9471a0dfb36a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8541 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# iterate over all genes and generate protein-level consensus annotation\n",
    "Graph_based_loc_annot = []\n",
    "\n",
    "for idx, gene in tqdm(enumerate(all_genes), total=len(all_genes)): \n",
    "    neighbor_list, neighbor_annot_list = gene_neighbor_annots(gene_name=gene, adata=adata, annot_df=annot_df, gene_name_col=\"Gene_name_canonical\", annot_col=\"cluster_annotation\")\n",
    "    # get the most common annotation in the neighbor annotation\n",
    "    most_common_annot = Counter(neighbor_annot_list).most_common(1)[0][0]\n",
    "    Graph_based_loc_annot.append(most_common_annot)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of proteins with unclassified graph-based annotation: 1034\n"
     ]
    }
   ],
   "source": [
    "# add the consensus annotation to the dataframe\n",
    "annot_df[\"Graph-based_localization_annotation\"] = Graph_based_loc_annot\n",
    "annot_df[\"consensus_graph_annnotation\"] = Graph_based_loc_annot  # initialize the column\n",
    "\n",
    "# for proteins where the graph-based annotation is unclassified, use the cluster annotation\n",
    "mask = annot_df[\"Graph-based_localization_annotation\"] == \"unclassified\"\n",
    "print(\"Number of proteins with unclassified graph-based annotation:\", sum(mask))\n",
    "annot_df.loc[mask, \"consensus_graph_annnotation\"] = annot_df.loc[mask, \"cluster_annotation\"]\n",
    "\n",
    "# save the annotation table\n",
    "annot_df.to_csv(save_path / f\"{timestamp}_graph-based_annotations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\duo.peng\\AppData\\Roaming\\Python\\Python310\\site-packages\\anndata\\_core\\anndata.py:1228: FutureWarning: The `inplace` parameter in pandas.Categorical.reorder_categories is deprecated and will be removed in a future version. Reordering categories will always return a new Categorical object.\n",
      "  c.reorder_categories(natsorted(c.categories), inplace=True)\n",
      "... storing 'Graph-based_localization_annotation' as categorical\n",
      "C:\\Users\\duo.peng\\AppData\\Roaming\\Python\\Python310\\site-packages\\anndata\\_core\\anndata.py:1228: FutureWarning: The `inplace` parameter in pandas.Categorical.reorder_categories is deprecated and will be removed in a future version. Reordering categories will always return a new Categorical object.\n",
      "  c.reorder_categories(natsorted(c.categories), inplace=True)\n",
      "... storing 'consensus_graph_annnotation' as categorical\n"
     ]
    }
   ],
   "source": [
    "# add the annotations to the adata object\n",
    "adata.obs[\"Graph-based_localization_annotation\"] = annot_df[\"Graph-based_localization_annotation\"].to_list()\n",
    "adata.obs[\"consensus_graph_annnotation\"] = annot_df[\"consensus_graph_annnotation\"].to_list()\n",
    "# save a copy of the (updated) adata object, overwriting the previous one\n",
    "adata_path = save_path / f\"adata_kNN_{timestamp}.h5ad\"\n",
    "adata.write(adata_path)\n",
    "\n",
    "# add the annotations to the umap_table\n",
    "umap_table.insert(6, \"consensus_graph_annnotation\", annot_df[\"consensus_graph_annnotation\"].to_list())\n",
    "umap_table.insert(6, \"Graph-based_localization_annotation\", annot_df[\"Graph-based_localization_annotation\"].to_list())\n",
    "# save a copy of the (updated) umap_table\n",
    "umap_table.to_csv(save_path / f\"{timestamp}_umap_table.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orgIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
