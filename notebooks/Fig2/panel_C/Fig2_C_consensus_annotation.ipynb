{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig. 2 panel C protein-level concensus annotation\n",
    "\n",
    "This notebook generates two sets of annotations:\n",
    "- Graph-based_localization_annotation  \n",
    "  For each protein, this is the most common annotation in the neighbor annotation \n",
    "- consensus_graph_annnotation\n",
    "  Based on the graph-based localization annotation, for proteins where the graph-based annotation is unclassified, use the cluster annotation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import plotly.io as pio\n",
    "import umap\n",
    "import anndata as ad\n",
    "import umap.plot\n",
    "import random\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import anndata as ad\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "script_path = Path.cwd().parent.parent.parent / \"script\"\n",
    "data_path = Path.cwd().parent.parent.parent / \"data\"\n",
    "sys.path.append(str(script_path))\n",
    "from utils.label_processing import attach_annotations\n",
    "from external import clustering_workflows\n",
    "from utils.Jaccard_coefficient import *\n",
    "\n",
    "save_path = Path.cwd() / \"output\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the enrichment table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp = datetime.now().strftime('%Y-%m-%d')\n",
    "# print(f\"Timestamp: {timestamp}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually set the timestamp to use the intermediate results from another date\n",
    "timestamp = \"2023-10-21-imp5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define files to load\n",
    "enrichment_dir = Path.cwd().parent.parent / \"enrichment\"\n",
    "enrichment_csv_path = enrichment_dir / \"output\" / \"enrichment_and_volcano_tables\" / f'{timestamp}_enrichment_table_NOC_prop.csv'\n",
    "\n",
    "try:\n",
    "    # load the file\n",
    "    enrichments = pd.read_csv(enrichment_csv_path, header=[0,1], index_col=0)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File {enrichment_csv_path} not found.\\nPlease run the enrichment analysis first or specify the correct timestamp, current value is {timestamp}\")\n",
    "except pd.errors.ParserError:\n",
    "    print(f\"There was an error parsing the CSV file at {enrichment_csv_path}.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the enrichment metadata columns\n",
    "# enrichments[\"metadata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the sample columns\n",
    "# enrichments[\"sample\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach canonical gene names\n",
    "gene_name_csv = data_path / \"external\" / \"canonical_names_and_Itzhak_data.csv\"\n",
    "\n",
    "lookup_table = pd.read_csv(gene_name_csv)\n",
    "to_df = enrichments[\"metadata\"].copy()\n",
    "list_of_cols_to_add = reversed([\"Gene_name_canonical\"])\n",
    "for c in list_of_cols_to_add:\n",
    "    new_col_data = attach_annotations(from_df=lookup_table, to_df=to_df, anno_col=c , from_on=\"Majority protein IDs\", to_on=\"Majority protein IDs\")\n",
    "    enrichments[(\"metadata\", \"Gene_name_canonical\")] = new_col_data\n",
    "\n",
    "# attach ground truth\n",
    "ground_truth_csv = data_path / \"external\" / \"organelle_curated_ground_truth_v6.0.csv\"\n",
    "\n",
    "lookup_table = pd.read_csv(ground_truth_csv)\n",
    "to_df = enrichments[\"metadata\"].copy()\n",
    "list_of_cols_to_add = reversed([\"organelle\"])\n",
    "for c in list_of_cols_to_add:\n",
    "    new_col_data = attach_annotations(from_df=lookup_table, to_df=to_df, anno_col=c , from_on=\"gene_name_canonical\", to_on=\"Gene_name_canonical\")\n",
    "    enrichments[(\"metadata\", \"organelle_ground_truth_v6.0\")] = new_col_data\n",
    "\n",
    "# attach labels\n",
    "labels_csv = data_path / \"labels\" / \"cluster_annotation_Dec6.csv\"\n",
    "\n",
    "lookup_table = pd.read_csv(labels_csv)\n",
    "to_df = enrichments[\"metadata\"].copy()\n",
    "list_of_cols_to_add = reversed([\"cluster_annotation\"])\n",
    "for c in list_of_cols_to_add:\n",
    "    new_col_data = attach_annotations(from_df=lookup_table, to_df=to_df, anno_col=c , from_on=\"Majority protein IDs\", to_on=\"Majority protein IDs\")\n",
    "    enrichments[(\"metadata\", \"cluster_annotation\")] = new_col_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample selection for the Leiden and the UMAP algorithms, NOTE: manual sample removal is NOT in this cell\n",
    "\n",
    "# there are some superfluous samples in this table as well as WTs \n",
    "# these dont help too much in separating organelles so not counting them\n",
    "# we also remove the infected samples here as those shouldn't be used in calculating the reference UMAP\n",
    "cols = list(enrichments['sample'])\n",
    "meta_cols = list(enrichments['metadata'])\n",
    "samples = [x for x in cols if \n",
    "    'WT' not in x and 'harsh' not in x and 'unsorted' not in x and \"Infected\" not in x]\n",
    "\n",
    "# next, we remove additional samples using bait names \n",
    "genes = [x.split('-')[1] if '-' in x else x for x in samples]\n",
    "sample_table = pd.DataFrame()\n",
    "sample_table['samples'] = samples\n",
    "sample_table['bait'] = genes\n",
    "\n",
    "bait_drop_list = ['EXOC2'] # here we are just removing EXOC2\n",
    "selected_samples = []\n",
    "for index, row in sample_table.iterrows():\n",
    "    if row['bait'] not in bait_drop_list:\n",
    "        selected_samples.append(row['samples'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of selected samples is 69\n",
      "the selected samples are ['01-CAPRIN1', '02-ATG101', '02-COPE', '02-DCP1A', '02-GOLGA2', '02-RICTOR', '03-HSP90AA', '03-HSPA1B', '03-SEC23A', '05-CAV1', '05-EDC4', '05-NCLN', '06-ATP6V1B2', '06-CCDC47', '06-CSNK2A1', '06-CSNK2A2', '06-YWHAB', '07-AP4B1', '07-CLTA', '07-COG8', '07-RAPTOR', '09-ATG101', '09-EDC4', '09-HSP90AA1', '09-PEX3', '09-PSMB7', '09-TOMM20', '10-AP2B1', '10-RTN4', '10-TOMM20', '10-VPS35', '11-CEP350', '11-EEA1', '11-GPR107', '11-SEC31A', '12-ACTB', '12-G3BP1', '12-LAMP1', '12-PNPLA2', '12-RTN4', '12-SEC61B', '12-TOMM20', '12-YWHAQ', '13-GOLGA2', '13-RAB11A', '13-RAB14', '13-RAB1A', '13-RAB7A', '14-COPE', '14-GOLGA2', '14-RAB11A', '14-RAB14', '14-RAB1A', '14-RAB7A', '15-G3BP1', '15-GOLGA2', '15-LAMP1', '15-MAP1LC3B', '15-SEC61B', '15-TOMM20', '17-ATP1B3', '17-CAPRIN1', '17-G3BP1', '17-MAP1LC3B', '17-RPL36', '17-SLC30A2', 'NOC_cytosol', 'NOC_nuclear', 'NOC_organelle']\n"
     ]
    }
   ],
   "source": [
    "# check the selected samples\n",
    "print(f\"the number of selected samples is {len(selected_samples)}\")\n",
    "print(f\"the selected samples are {sorted(selected_samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually drop a few samples \n",
    "to_drop = [\"02-EXOC2\",\"06-ATP6V1B2\",\"06-CSNK2A1\", \"06-CSNK2A2\", \"07-AP4B1\", '02-RICTOR', \"07-RAPTOR\", \"10-AP2B1\", \"12-PNPLA2\"] #  for example: to_drop = [\"09-HSP90AA1\", \"09-PSMB7\"]\n",
    "selected_samples = [x for x in selected_samples if x not in to_drop] # update the variable: selected_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of selected samples is 61\n",
      "the selected samples are ['01-CAPRIN1', '02-ATG101', '02-COPE', '02-DCP1A', '02-GOLGA2', '03-HSP90AA', '03-HSPA1B', '03-SEC23A', '05-CAV1', '05-EDC4', '05-NCLN', '06-CCDC47', '06-YWHAB', '07-CLTA', '07-COG8', '09-ATG101', '09-EDC4', '09-HSP90AA1', '09-PEX3', '09-PSMB7', '09-TOMM20', '10-RTN4', '10-TOMM20', '10-VPS35', '11-CEP350', '11-EEA1', '11-GPR107', '11-SEC31A', '12-ACTB', '12-G3BP1', '12-LAMP1', '12-RTN4', '12-SEC61B', '12-TOMM20', '12-YWHAQ', '13-GOLGA2', '13-RAB11A', '13-RAB14', '13-RAB1A', '13-RAB7A', '14-COPE', '14-GOLGA2', '14-RAB11A', '14-RAB14', '14-RAB1A', '14-RAB7A', '15-G3BP1', '15-GOLGA2', '15-LAMP1', '15-MAP1LC3B', '15-SEC61B', '15-TOMM20', '17-ATP1B3', '17-CAPRIN1', '17-G3BP1', '17-MAP1LC3B', '17-RPL36', '17-SLC30A2', 'NOC_cytosol', 'NOC_nuclear', 'NOC_organelle']\n"
     ]
    }
   ],
   "source": [
    "# check the selected samples after manual sample removal\n",
    "print(f\"the number of selected samples is {len(selected_samples)}\")\n",
    "print(f\"the selected samples are {sorted(selected_samples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dimensions of the data table saved for UMAP are (8541, 61)\n"
     ]
    }
   ],
   "source": [
    "# save a copy of the tables for UMAP\n",
    "\n",
    "umap_table = enrichments.droplevel(0, axis=1)[meta_cols + selected_samples].copy()\n",
    "# normalization and UMAP algorithm are not compatible with any NaN values, so drop them \n",
    "umap_table = umap_table.dropna(subset=selected_samples)\n",
    "quants = umap_table[selected_samples].copy()\n",
    "print(f\"the dimensions of the data table saved for UMAP are {quants.shape}\")\n",
    "\n",
    "quants.to_csv(save_path / f\"{timestamp}_quants.csv\")\n",
    "umap_table.to_csv(save_path / f\"{timestamp}_umap_table.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert data into anndata format \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\duo.peng\\AppData\\Roaming\\Python\\Python310\\site-packages\\anndata\\_core\\anndata.py:120: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n",
      "C:\\Users\\duo.peng\\AppData\\Roaming\\Python\\Python310\\site-packages\\anndata\\_core\\anndata.py:1228: FutureWarning: The `inplace` parameter in pandas.Categorical.reorder_categories is deprecated and will be removed in a future version. Reordering categories will always return a new Categorical object.\n",
      "  c.reorder_categories(natsorted(c.categories), inplace=True)\n",
      "... storing 'Gene_name_canonical' as categorical\n",
      "C:\\Users\\duo.peng\\AppData\\Roaming\\Python\\Python310\\site-packages\\anndata\\_core\\anndata.py:1228: FutureWarning: The `inplace` parameter in pandas.Categorical.reorder_categories is deprecated and will be removed in a future version. Reordering categories will always return a new Categorical object.\n",
      "  c.reorder_categories(natsorted(c.categories), inplace=True)\n",
      "... storing 'organelle_ground_truth_v6.0' as categorical\n",
      "C:\\Users\\duo.peng\\AppData\\Roaming\\Python\\Python310\\site-packages\\anndata\\_core\\anndata.py:1228: FutureWarning: The `inplace` parameter in pandas.Categorical.reorder_categories is deprecated and will be removed in a future version. Reordering categories will always return a new Categorical object.\n",
      "  c.reorder_categories(natsorted(c.categories), inplace=True)\n",
      "... storing 'cluster_annotation' as categorical\n"
     ]
    }
   ],
   "source": [
    "# generating AnnData\n",
    "selected = enrichments['sample'][selected_samples].copy()\n",
    "adata = ad.AnnData(selected)\n",
    "\n",
    "adata.var_names = selected.columns.to_list()\n",
    "adata.obs_names = enrichments['metadata'][\"Protein IDs\"].to_list()\n",
    "adata.obs[\"Protein IDs\"] = enrichments['metadata'][\"Protein IDs\"].to_list()\n",
    "adata.obs[\"Majority protein IDs\"] = enrichments['metadata'][\"Majority protein IDs\"].to_list()\n",
    "adata.obs[\"Gene_name_canonical\"] = enrichments['metadata'][\"Gene_name_canonical\"].to_list()\n",
    "adata.obs[\"organelle_ground_truth_v6.0\"] = enrichments['metadata'][\"organelle_ground_truth_v6.0\"].to_list()\n",
    "adata.obs[\"cluster_annotation\"] = enrichments['metadata'][\"cluster_annotation\"].to_list()\n",
    "\n",
    "adata.write_h5ad(save_path / f\"adata_{timestamp}.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute knn graph (and save a copy for later use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a clusteringworkflow class (to use the part of workflow that computes the nearest neighbor graph)\n",
    "kNN_obj = clustering_workflows.ClusteringWorkflow(adata=copy.deepcopy(adata))\n",
    "# preprocessing\n",
    "kNN_obj.preprocess(n_pcs=None)\n",
    "# compute nearest neighbor graph\n",
    "kNN_obj.calculate_neighbors(n_pcs=None, n_neighbors=20)\n",
    "adata = kNN_obj.adata\n",
    "# save a copy of the adata object that contains the kNN graph\n",
    "knn_adata_path = save_path / f\"adata_kNN_{timestamp}.h5ad\"\n",
    "adata.write(knn_adata_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate protein-level consensus annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_majority_ids = adata.obs[\"Majority protein IDs\"].to_list()\n",
    "all_genes = adata.obs[\"Gene_name_canonical\"].to_list()\n",
    "\n",
    "annot_df = pd.DataFrame(list(zip(\n",
    "    adata.obs[\"Majority protein IDs\"].to_list(),\n",
    "    adata.obs[\"Gene_name_canonical\"].to_list(),\n",
    "    adata.obs[\"cluster_annotation\"].to_list())),\n",
    "    columns=[\"Majority protein IDs\", \"Gene_name_canonical\", \"cluster_annotation\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe8c10ccc2242c799988bc14f35aa06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8541 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# iterate over all genes and generate protein-level consensus annotation\n",
    "Graph_based_loc_annot = []\n",
    "\n",
    "for idx, gene in tqdm(enumerate(all_genes), total=len(all_genes)): \n",
    "    neighbor_list, neighbor_annot_list = gene_neighbor_annots(gene_name=gene, adata=adata, annot_df=annot_df, gene_name_col=\"Gene_name_canonical\", annot_col=\"cluster_annotation\")\n",
    "    # get the most common annotation in the neighbor annotation\n",
    "    most_common_annot = Counter(neighbor_annot_list).most_common(1)[0][0]\n",
    "    Graph_based_loc_annot.append(most_common_annot)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of proteins with unclassified graph-based annotation: 1058\n"
     ]
    }
   ],
   "source": [
    "# add the consensus annotation to the dataframe\n",
    "annot_df[\"Graph-based_localization_annotation\"] = Graph_based_loc_annot\n",
    "annot_df[\"consensus_graph_annnotation\"] = Graph_based_loc_annot # initialize the column\n",
    "\n",
    "# for proteins where the graph-based annotation is unclassified, use the cluster annotation\n",
    "mask = annot_df[\"Graph-based_localization_annotation\"] == \"unclassified\"\n",
    "print(\"Number of proteins with unclassified graph-based annotation:\", sum(mask))\n",
    "annot_df.loc[mask, \"consensus_graph_annnotation\"] = annot_df.loc[mask, \"cluster_annotation\"]\n",
    "\n",
    "# save the annotation table\n",
    "annot_df.to_csv(save_path / f\"{timestamp}_graph-based_annotations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\duo.peng\\AppData\\Roaming\\Python\\Python310\\site-packages\\anndata\\_core\\anndata.py:1228: FutureWarning: The `inplace` parameter in pandas.Categorical.reorder_categories is deprecated and will be removed in a future version. Reordering categories will always return a new Categorical object.\n",
      "  c.reorder_categories(natsorted(c.categories), inplace=True)\n",
      "... storing 'Graph-based_localization_annotation' as categorical\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\duo.peng\\AppData\\Roaming\\Python\\Python310\\site-packages\\anndata\\_core\\anndata.py:1228: FutureWarning: The `inplace` parameter in pandas.Categorical.reorder_categories is deprecated and will be removed in a future version. Reordering categories will always return a new Categorical object.\n",
      "  c.reorder_categories(natsorted(c.categories), inplace=True)\n",
      "... storing 'consensus_graph_annnotation' as categorical\n"
     ]
    }
   ],
   "source": [
    "# add the annotations to the adata object\n",
    "adata.obs[\"Graph-based_localization_annotation\"] = annot_df[\"Graph-based_localization_annotation\"].to_list()\n",
    "adata.obs[\"consensus_graph_annnotation\"] = annot_df[\"consensus_graph_annnotation\"].to_list()\n",
    "# save a copy of the (updated) adata object, overwriting the previous one\n",
    "adata_path = save_path / f\"adata_kNN_{timestamp}.h5ad\"\n",
    "adata.write(adata_path)\n",
    "\n",
    "# add the annotations to the umap_table\n",
    "umap_table.insert(6, \"consensus_graph_annnotation\", annot_df[\"consensus_graph_annnotation\"].to_list())\n",
    "umap_table.insert(6, \"Graph-based_localization_annotation\", annot_df[\"Graph-based_localization_annotation\"].to_list())\n",
    "# save a copy of the (updated) umap_table\n",
    "umap_table.to_csv(save_path / f\"{timestamp}_umap_table.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orgIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
